#!/usr/bin/env sh

{{ansible_managed|comment(decoration='#')}}

# SHELL VARIABLES

SHELL='/bin/sh'
PATH='/sbin:/bin:/usr/sbin:/usr/bin'

# COMMANDS

which='/usr/bin/which' && [ -x ${which} ] || { echo "Error: Command 'which' not found."; exit 127; }
basename=$(${which} basename) || { echo "Error: Command 'basename' not found."; exit 127; }
date=$(${which} date) || { echo "Error: Command 'date' not found."; exit 127; }
echo=$(${which} echo) || { echo "Error: Command 'echo' not found."; exit 127; }
expr=$(${which} expr) || { echo "Error: Command 'expr' not found."; exit 127; }
grep=$(${which} grep) || { echo "Error: Command 'grep' not found."; exit 127; }
hostname=$(${which} hostname) || { echo "Error: Command 'hostname' not found."; exit 127; }
logger=$(${which} logger) || { echo "Error: Command 'logger' not found."; exit 127; }
{% if (zfs_monitor_mail_state is match('true|yes|enable')) %}
mailx=$(${which} mailx) || { echo "Error: Command 'mailx' not found."; exit 127; }
{% endif %}
rm=$(${which} rm) || { echo "Error: Command 'rm' not found."; exit 127; }
sleep=$(${which} sleep) || { echo "Error: Command 'sleep' not found."; exit 127; }
touch=$(${which} touch) || { echo "Error: Command 'touch' not found."; exit 127; }
whoami=$(${which} whoami) || { echo "Error: Command 'whoami' not found."; exit 127; }

zpool=$(${which} zpool) || { echo "Error: Command 'zpool' not found."; exit 127; }

# VARIABLES

host=$(${hostname} -s) || { echo "Error: Host name unknown."; exit 68; }
script="$(${basename} $0)[$$]" || { echo "Error: Command invoked cannot execute."; exit 126; }
time_start=$(${date} '+%s')
user='{{file_owner_zfs_scrub_pools}}'
lockfile='/var/tmp/zfs_scrub-pools.lock'
retval=0
severity='Debug'
message='Please check log files for more information.'

textfile_collector='{{zfs_monitor_prom_textfile_collector}}'
zfs_scrub_pools_pools='{% for item in zfs_scrub_pools_pools %}{{item}}{% if not loop.last %} {% endif %}{% endfor %}'

{% if (zfs_monitor_mail_state is match('true|yes|enable')) %}
mail_from_address='{{zfs_monitor_mail_from_address}}'
mail_to_address='{% for item in zfs_monitor_mail_to_address %}{{item}}{% if not loop.last %},{% endif %}{% endfor %}'
mail_subject='zfs: Scrub Pool - Error ({{ansible_hostname}})'
{% endif %}

# FUNCTIONS

{% if (zfs_monitor_mail_state is match('true|yes|enable')) %}
mail_error() {
  retval="$1"
  severity="$2"
  message="$3"
  mail_body="ERROR

Message     : ${message}
Severity    : ${severity}
Date & Time : $(${date} '+%Y-%m-%dT%H:%M:%S%z')

SCRIPT

Name        : zfs_scrub-pools
Type        : Shell script
PID         : $$

SYSTEM

Hostname    : {{ansible_hostname}}
FQDN        : {{ansible_fqdn}}"

{% if (ansible_os_family == 'FreeBSD') %}
  ${echo} "${mail_body}" | ${mailx} -s "${mail_subject}" -F "${mail_to_address}" > /dev/null 2>&1
{% else %}
  ${echo} "${mail_body}" | ${mailx} -r "${mail_from_address}" -s "${mail_subject}" "${mail_to_address}" > /dev/null 2>&1
{% endif %}
}
{% endif %}

{% if (zfs_monitor_prom_state is match('true|yes|enable')) %}
update_prom() {
  retval="$1"
  time_start="$2"
  time_exec="$3"

  if [ -w "${textfile_collector}" ]; then
    ${echo} "# HELP zfs_scrub_pools_exit The script's exit code.
# TYPE zfs_scrub_pools_exit counter
zfs_scrub_pools_exit ${retval}" > "${textfile_collector}/zfs_scrub_pools_exit.prom"

    if [ -z "${time_start}" ] ; then
      ${rm} -f "${textfile_collector}/zfs_scrub_pools_start.prom"
    else
      ${echo} "# HELP zfs_scrub_pools_start The script's start time in epoch.
# TYPE zfs_scrub_pools_start counter
zfs_scrub_pools_start ${time_start}" > "${textfile_collector}/zfs_scrub_pools_start.prom"
    fi

    if [ -z "${time_exec}" ] ; then
      ${rm} -f "${textfile_collector}/zfs_scrub_pools_duration.prom"
    else
      ${echo} "# HELP zfs_scrub_pools_duration The script's execution duration in seconds.
# TYPE zfs_scrub_pools_duration counter
zfs_scrub_pools_duration ${time_exec}" > "${textfile_collector}/zfs_scrub_pools_duration.prom"
    fi
  fi
}
{% endif %}

watch_and_wait_for_change() {
  watch_key="$1"
  watch_value="$2"
  watch_option="$3"
  time_step="$4"
  time_maximum="$5"
  while ${watch_key} | ${grep} ${watch_option} "${watch_value}" > /dev/null 2>&1 ; do
    if [ "${time_initial}" -lt "${time_maximum}" ]; then
      time_initial=$(${expr} "${time_initial}" + "${time_step}")
      ${sleep} "${time_initial}"
    else
      ${sleep} "${time_initial}"
    fi
  done
}

check_script_user() {
  if [ "$(${whoami})" != "${user}" ]; then
    retval=77
    severity='Error'
    message="Please run script as user '${user}'"
    ${echo} "$(${date} '+%Y-%m-%dT%H:%M:%S%z') - ${host} - ${script}: ${severity}: ${message}"
    exit "${retval}"
  fi
}

create_lockfile() {
  if [ ! -e "${lockfile}" ]; then
    ${touch} "${lockfile}" || log_and_exit_on_error "$?" 'Warning' 'Could not create lockfile. Please investigate.'
  else
    log_and_exit_on_error "$?" 'Warning' 'Lockfile does already exist. Please investigate.'
  fi
}

remove_lockfile() {
  if [ -e "${lockfile}" ]; then
    ${rm} -f "${lockfile}" || log_and_exit_on_error "$?" 'Warning' 'Could not remove lockfile. Please investigate.'
  else
    log_and_exit_on_error "$?" 'Warning' 'Lockfile did not exist. Please investigate.'
  fi
}

log_and_exit_on_error() {
  retval="$1"
  severity="$2"
  message="$3"
  if [ "${retval}" -ne 0 ]; then
    ${rm} -f "${lockfile}"
    if [ -t 1 ] ; then
      ${echo} "$(${date} '+%Y-%m-%dT%H:%M:%S%z') - ${host} - ${script}: ${severity}: ${message}"
    fi
    ${logger} -t "${script}" "${severity}: ${message}"
{% if (zfs_monitor_mail_state is match('true|yes|enable')) %}
    mail_error "${retval}" "${severity}" "${message}"
{% endif %}

{% if (zfs_monitor_prom_state is match('true|yes|enable')) %}
    update_prom "${retval}" "${time_start}" "${time_exec}"
{% endif %}

    exit "${retval}"
  fi
}

log_and_exit() {
  time_end=$(${date} '+%s')
  time_exec=$(${expr} "${time_end}" - "${time_start}")
  time_hr=$(${date} -u -r "${time_exec}" '+%H:%M:%S')

  retval=0
  severity='Info'
  if [ -z "${zfs_scrub_pools_pools}" ]; then
    message='No ZFS pools have been specified for scrubbing.'
  else
    message='Specified ZFS pools have been scrubbed and are healthy.'
  fi
  ${logger} -t "${script}" "${severity}: ${message} Duration: ${time_hr}"

{% if (zfs_monitor_prom_state is match('true|yes|enable')) %}
  update_prom "${retval}" "${time_start}" "${time_exec}"
{% endif %}

  exit "${retval}"
}

# SCRIPT

check_script_user

create_lockfile

# Scrub ZFS pools
for pool in ${zfs_scrub_pools_pools} ; do
  # Wait until previous scrub has finished
  time_initial=0
  watch_and_wait_for_change "${zpool} status" 'scrub in progress' '' '5' '300'

  # Scrub next ZFS pool
  ${zpool} scrub ${pool}
  log_and_exit_on_error "$?" 'Error' "Unable to scrub ZFS pool: '${pool}'"
done

# Check ZFS pools
for pool in ${zfs_scrub_pools_pools} ; do
  # Wait until previous scrub has finished
  time_initial=0
  watch_and_wait_for_change "${zpool} status" 'scrub in progress' '' '5' '300'

  # Get next ZFS pool status
  zfs_pool_status="$(${zpool} status -xv ${pool})"
  log_and_exit_on_error "$?" 'Error' "Unable to get ZFS pool status: '${pool}'"

  # Check next ZFS pool status
  echo "${zfs_pool_status}" | ${grep} 'healthy' > /dev/null 2>&1
  if [ "$?" -eq 0 ]; then
    severity='Info'
    message="ZFS pool has been scrubbed and is healthy: '${pool}'"
    ${logger} -t "${script}" "${severity}: ${message}"
  else
    log_and_exit_on_error "$?" 'Critical' "ZFS pool is unhealthy: '${pool}'"
  fi
done

remove_lockfile

log_and_exit
